{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10224133,"sourceType":"datasetVersion","datasetId":6276900}],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# # Setting up\n\n# %% [code]\n!pip install ultralytics torch torchvision\n!pip install opencv-python\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-17T09:54:18.390803Z\",\"iopub.execute_input\":\"2024-12-17T09:54:18.391235Z\",\"iopub.status.idle\":\"2024-12-17T09:54:18.395811Z\",\"shell.execute_reply.started\":\"2024-12-17T09:54:18.391202Z\",\"shell.execute_reply\":\"2024-12-17T09:54:18.394934Z\"}}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom ultralytics import YOLO\nimport cv2\nimport random\nimport os\n\n# %% [markdown]\n# # Training custom weights\n# - train the model for custom data.yaml\n\n# %% [code]\n\n# Path to the custom YAML file\nDATA_YAML_PATH = \"/kaggle/input/police-uniform/Police uniform detection.v1i.yolov11/data.yaml\"  # Update this to the correct path\n\n# Path to a pre-trained YOLOv8 model weights or \"yolov8n.pt\", \"yolov8s.pt\", etc.\nMODEL_WEIGHTS = \"yolo11m.pt\"  # Start with a smaller model for experimentation\n\n# Directory to save trained model weights\nSAVE_DIR = \"/kaggle/working/runs/trained_weights\"\n\n# Training parameters\nTRAINING_PARAMS = {\n    \"data\": DATA_YAML_PATH,\n    \"epochs\": 50,          # Number of training epochs\n    \"imgsz\": 640,          # Image size for training\n    \"batch\": 16,           # Batch size\n    \"device\": \"0\",        # GPU ID (\"0\" for the first GPU; \"cpu\" to use CPU)\n    \"name\": \"custom_yolo\", # Run name for easier identification\n    \"cache\": True,         # Cache dataset for faster training\n    \"save_dir\": SAVE_DIR   # Directory to save training results and weights\n}\n\n\n# Ensure save directory exists\nos.makedirs(SAVE_DIR, exist_ok=True)\n\n# Load the model with the pre-trained weights\nmodel = YOLO(MODEL_WEIGHTS)\n\n# Train the model with the specified parameters\nresults = model.train(**TRAINING_PARAMS)\n\n# Save the trained model weights\nbest_weights_path = os.path.join(SAVE_DIR, \"custom_yolo_best.pt\")\nlast_weights_path = os.path.join(SAVE_DIR, \"custom_yolo_last.pt\")\n\n# Save best and last weights\nmodel.save(best_weights_path)\nprint(f\"Best model weights saved to: {best_weights_path}\")\n\n# Optional: If you want to save the last epoch weights separately\nmodel.save(last_weights_path)\nprint(f\"Last epoch model weights saved to: {last_weights_path}\")\n\n\n# %% [markdown]\n# # Predictions\n# - model initialization\n# - predict and display results\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-17T09:47:52.192484Z\",\"iopub.execute_input\":\"2024-12-17T09:47:52.192921Z\",\"iopub.status.idle\":\"2024-12-17T09:47:52.202942Z\",\"shell.execute_reply.started\":\"2024-12-17T09:47:52.192869Z\",\"shell.execute_reply\":\"2024-12-17T09:47:52.202097Z\"}}\nclass WeightSwitcherModel:\n    def __init__(self, weight_path_1, weight_path_2):\n        \"\"\"\n        Initialize the model with two weight paths.\n        \n        Args:\n            weight_path_1 (str): Path to the first weight file.\n            weight_path_2 (str): Path to the second weight file.\n        \"\"\"\n        self.weight_path_1 = weight_path_1\n        self.weight_path_2 = weight_path_2\n        self.model_1 = YOLO(self.weight_path_1)\n        self.model_2 = YOLO(self.weight_path_2)\n\n    def detect_image(self, image_path, custom_weights=True):\n        \"\"\"\n        Perform object detection on an image.\n\n        Args:\n            image_path (str): Path to the input image.\n            use_first_weight (bool): Whether to use the first weight or the second.\n\n        Returns:\n            detections (list): A list of detections with bounding boxes, class names, and confidence scores.\n        \"\"\"\n        model = self.model_2 if custom_weights else self.model_1\n        results = model(image_path,save = True)\n        return results\n\n# visualization function\n\ndef visualize_predictions(image_path, results):\n    \"\"\"\n    Visualize the detection results on the image and save the output.\n\n    Args:\n        image_path (str): Path to the input image.\n        detections (list): A list of detections with bounding boxes, class names, and confidence scores.\n        output_path (str): Path to save the output image.\n    \"\"\"\n    boxes = results.boxes.xyxy.cpu().numpy()  # Bounding box coordinates (x_min, y_min, x_max, y_max)\n    scores = results.boxes.conf.cpu().numpy()  # Confidence scores\n    class_ids = results.boxes.cls.cpu().numpy().astype(int)  # Class IDs\n    class_names = results.names  # Class names from the model\n\n    # Load the image\n    image = cv2.imread(image_path)  # Assuming results include original image path\n    if image is None:\n        print(\"Error: Unable to load image.\")\n        return\n\n    # Generate unique colors for each class\n    unique_classes = set(class_ids)\n    class_colors = {class_id: [random.randint(0, 255) for _ in range(3)] for class_id in unique_classes}\n\n    # Draw bounding boxes and labels on the image\n    for box, class_id in zip(boxes, class_ids):\n        x_min, y_min, x_max, y_max = map(int, box)\n        color = class_colors[class_id]\n        class_name = class_names[class_id]\n\n        # Draw the bounding box\n        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n\n        # Draw the class name label\n        label = f\"{class_name}\"\n        (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n        cv2.rectangle(image, (x_min, y_min - label_height - baseline), (x_min + label_width, y_min), color, -1)\n        cv2.putText(image, label, (x_min, y_min - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n\n    plt.imshow(image)\n    plt.show()\n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-17T09:47:54.524278Z\",\"iopub.execute_input\":\"2024-12-17T09:47:54.525004Z\",\"iopub.status.idle\":\"2024-12-17T09:47:54.529043Z\",\"shell.execute_reply.started\":\"2024-12-17T09:47:54.524970Z\",\"shell.execute_reply\":\"2024-12-17T09:47:54.528001Z\"}}\nimage_path = '/kaggle/input/police-uniform/Police uniform detection.v1i.yolov11/train/images/Image_25_jpg.rf.521641d96169c3c4e7f797ec8f32d0e8.jpg'\ngeneral_model = 'yolo11m.pt'\ncustom_weight = '/kaggle/working/runs/detect/custom_yolo2/weights/best.pt'\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-17T09:48:09.194774Z\",\"iopub.execute_input\":\"2024-12-17T09:48:09.195163Z\",\"iopub.status.idle\":\"2024-12-17T09:48:10.052633Z\",\"shell.execute_reply.started\":\"2024-12-17T09:48:09.195132Z\",\"shell.execute_reply\":\"2024-12-17T09:48:10.051821Z\"}}\nmodel = WeightSwitcherModel(general_model, custom_weight)\nresults = model.detect_image(image_path, custom_weights=True)\nvisualize_predictions(image_path, results[0])\n\n# %% [markdown]\n# ## confidence Calculation\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-17T09:54:36.236395Z\",\"iopub.execute_input\":\"2024-12-17T09:54:36.237102Z\",\"iopub.status.idle\":\"2024-12-17T09:54:37.169236Z\",\"shell.execute_reply.started\":\"2024-12-17T09:54:36.237052Z\",\"shell.execute_reply\":\"2024-12-17T09:54:37.168372Z\"}}\ncustom_weight = '/kaggle/working/runs/detect/custom_yolo2/weights/best.pt'\nimage_path = '/kaggle/input/police-uniform/Police uniform detection.v1i.yolov11/train/images/Image_25_jpg.rf.521641d96169c3c4e7f797ec8f32d0e8.jpg'\n\npolice_model = YOLO(custom_weight)\n\n# Perform detection on an input image\npolice_results = police_model(image_path)\n\n# Extract police detections\npolice_detections = []\nfor r in police_results:\n    for box in r.boxes:\n        conf = box.conf[0]  # Confidence score\n        xyxy = box.xyxy[0].tolist()  # Bounding box coordinates\n        police_detections.append((xyxy, conf))\n\n# Load the pretrained YOLO model (for COCO classes)\nperson_model = YOLO(\"yolo11m.pt\")  # Replace with a suitable YOLO model\n\n# Perform detection on the same image\nperson_results = person_model(image_path)\n\n# Extract person detections\nperson_detections = []\nfor r in person_results:\n    for box in r.boxes:\n        cls_id = int(box.cls[0])  # Class ID\n        conf = box.conf[0]       # Confidence score\n        if cls_id == 0:  # COCO 'person' class ID is 0\n            xyxy = box.xyxy[0].tolist()\n            person_detections.append((xyxy, conf))\n\n\ndef calculate_iou(box1, box2):\n    # Calculate intersection over union (IoU) for two bounding boxes\n    x1 = max(box1[0], box2[0])\n    y1 = max(box1[1], box2[1])\n    x2 = min(box1[2], box2[2])\n    y2 = min(box1[3], box2[3])\n\n    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n\n    union = area1 + area2 - intersection\n    return intersection / union if union > 0 else 0\n\n# Match police with person detections\nfor police_box, police_conf in police_detections:\n    for person_box, person_conf in person_detections:\n        iou = calculate_iou(police_box, person_box)\n        if iou > 0.5:  # IoU threshold for matching\n            print(f\"Police detected (IoU={iou:.2f}):\")\n            print(f\" - Police confidence: {police_conf:.2f}\")\n            print(f\" - Person confidence: {person_conf:.2f}\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-17T09:51:11.238788Z\",\"iopub.execute_input\":\"2024-12-17T09:51:11.239128Z\",\"iopub.status.idle\":\"2024-12-17T09:51:11.582137Z\",\"shell.execute_reply.started\":\"2024-12-17T09:51:11.239100Z\",\"shell.execute_reply\":\"2024-12-17T09:51:11.581305Z\"}}\nplt.figure(figsize=(8,14))\nplt.subplot(2,2,1)\nplt.title(\"custom weight\")\nimg1 = cv2.imread('/kaggle/working/runs/detect/predict13/Image_25_jpg.rf.521641d96169c3c4e7f797ec8f32d0e8.jpg')\nplt.axis(False)\nplt.imshow(img1)\nplt.subplot(2,2,2)\nplt.title(\"general weight\")\nimg2 = cv2.imread('/kaggle/working/runs/detect/predict12/Image_25_jpg.rf.521641d96169c3c4e7f797ec8f32d0e8.jpg')\nplt.axis(False)\nplt.imshow(img2)\nplt.show()\n\n# %% [code]\n","metadata":{"_uuid":"83c7eb56-b716-421a-b820-c005e1477769","_cell_guid":"67b81bbb-380c-4986-bfbd-098828832f0a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}