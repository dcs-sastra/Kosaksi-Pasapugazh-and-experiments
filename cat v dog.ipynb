{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8538994,"sourceType":"datasetVersion","datasetId":5100933}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n!pip install ultralytics\nfrom ultralytics import YOLO\nfrom IPython.display import clear_output\nclear_output()\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-28T15:06:51.143021Z","iopub.execute_input":"2024-05-28T15:06:51.143382Z","iopub.status.idle":"2024-05-28T15:07:17.421313Z","shell.execute_reply.started":"2024-05-28T15:06:51.143350Z","shell.execute_reply":"2024-05-28T15:07:17.420334Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\nmodel = YOLO(\"yolov8n.yaml\")\nfor name, param in model.named_parameters():\n    if 'model.model.22.cv3.2.1.conv.weight' in name or 'model.model.22.cv3.2.1.bn.weight' in name or 'model.model.22.cv3.2.1.bn.bias' in name or 'model.model.22.cv3.2.2.weight' in name or 'model.model.22.cv3.2.2.bias' in name:\n        param.requires_grad = True  # Freeze the parameters\n    else:\n        param.requires_grad = False\nr=model.train(data=\"/kaggle/input/1000-catv-dog/data.yaml\", epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T12:13:12.182212Z","iopub.execute_input":"2024-05-28T12:13:12.183348Z","iopub.status.idle":"2024-05-28T13:36:36.477824Z","shell.execute_reply.started":"2024-05-28T12:13:12.183300Z","shell.execute_reply":"2024-05-28T13:36:36.476858Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.23  Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/kaggle/input/1000-catv-dog/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|| 755k/755k [00:00<00:00, 25.5MB/s]\n2024-05-28 12:13:15,290\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-05-28 12:13:16,070\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \nYOLOv8n summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240528_121543-nlcbuat4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/arunnithyaanandam/YOLOv8/runs/nlcbuat4' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/arunnithyaanandam/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/arunnithyaanandam/YOLOv8' target=\"_blank\">https://wandb.ai/arunnithyaanandam/YOLOv8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/arunnithyaanandam/YOLOv8/runs/nlcbuat4' target=\"_blank\">https://wandb.ai/arunnithyaanandam/YOLOv8/runs/nlcbuat4</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/1000-catv-dog/train/labels... 3792 images, 0 backgrounds, 0 corrupt: 100%|| 3792/3792 [00:09<00:00, 379.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 Cache directory /kaggle/input/1000-catv-dog/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/1000-catv-dog/valid/labels... 361 images, 0 backgrounds, 0 corrupt: 100%|| 361/361 [00:01<00:00, 298.77it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 Cache directory /kaggle/input/1000-catv-dog/valid is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100      2.35G      2.737      3.255       3.47        111        640: 100%|| 237/237 [00:49<00:00,  4.76it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:04<00:00,  2.61it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.262      0.378      0.207       0.11\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100      2.32G      1.491      2.164      2.056        141        640: 100%|| 237/237 [00:44<00:00,  5.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.425      0.619      0.395      0.273\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100       2.3G      1.213      1.866      1.757        110        640: 100%|| 237/237 [00:44<00:00,  5.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.36it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.413      0.637      0.392      0.298\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100       2.3G      1.062      1.717      1.604        151        640: 100%|| 237/237 [00:44<00:00,  5.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.63it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.41      0.695      0.416      0.312\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      2.27G     0.9979      1.622      1.538        110        640: 100%|| 237/237 [00:44<00:00,  5.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:03<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.436      0.725      0.429      0.333\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100       2.3G     0.9355      1.558      1.476         88        640: 100%|| 237/237 [00:44<00:00,  5.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.444      0.722      0.439      0.346\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100       2.3G     0.8919      1.521      1.444        105        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.453      0.735      0.449      0.369\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100       2.3G     0.8349      1.464      1.391        139        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.63it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.462      0.731      0.459      0.358\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100       2.3G     0.8255      1.448      1.378        118        640: 100%|| 237/237 [00:45<00:00,  5.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.62it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.468      0.718      0.466      0.382\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100      2.27G     0.7959       1.41       1.35        135        640: 100%|| 237/237 [00:44<00:00,  5.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.40it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.464      0.747      0.479      0.403\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100       2.3G     0.7548      1.381      1.322         88        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.469      0.724      0.491      0.411\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100      2.16G     0.7508      1.368      1.312         98        640: 100%|| 237/237 [00:44<00:00,  5.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.474      0.736      0.528      0.439\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100       2.3G     0.7338      1.348      1.297        103        640: 100%|| 237/237 [00:44<00:00,  5.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.491       0.73      0.552      0.464\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100      2.29G     0.7189      1.324      1.284        119        640: 100%|| 237/237 [00:44<00:00,  5.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.448      0.782      0.507      0.418\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100      2.17G      0.715      1.329      1.282        127        640: 100%|| 237/237 [00:44<00:00,  5.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.468      0.735      0.544      0.452\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100      2.16G     0.7091      1.317      1.274        113        640: 100%|| 237/237 [00:43<00:00,  5.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.467      0.784      0.542      0.462\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/100       2.3G     0.6822      1.287      1.254        111        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.522      0.699      0.584      0.494\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/100      2.17G       0.67      1.258      1.242        130        640: 100%|| 237/237 [00:44<00:00,  5.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.499      0.725      0.596      0.515\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     19/100       2.3G       0.67      1.256      1.238         97        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.492      0.732      0.594      0.512\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     20/100      2.27G     0.6467      1.223      1.214        106        640: 100%|| 237/237 [00:44<00:00,  5.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.533      0.696      0.622      0.526\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     21/100      2.28G     0.6468      1.227      1.219        117        640: 100%|| 237/237 [00:44<00:00,  5.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.524       0.71      0.609      0.514\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     22/100      2.27G     0.6429      1.206      1.219        122        640: 100%|| 237/237 [00:44<00:00,  5.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.66it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.54      0.713      0.633      0.529\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     23/100      2.16G     0.6334      1.197      1.204        134        640: 100%|| 237/237 [00:44<00:00,  5.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.524      0.726      0.638      0.547\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     24/100      2.16G     0.6264      1.178      1.196        101        640: 100%|| 237/237 [00:45<00:00,  5.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.72it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.57      0.693      0.647      0.553\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     25/100       2.3G      0.622      1.167      1.197        124        640: 100%|| 237/237 [00:44<00:00,  5.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.545       0.72      0.653      0.569\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     26/100      2.17G     0.6073      1.142      1.178         98        640: 100%|| 237/237 [00:43<00:00,  5.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.72it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.565        0.7      0.662      0.569\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     27/100      2.16G     0.5989      1.123      1.173        128        640: 100%|| 237/237 [00:44<00:00,  5.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.579      0.705      0.683      0.594\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     28/100       2.3G     0.5964      1.126      1.169        137        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.57      0.738      0.693      0.612\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     29/100      2.18G     0.5948      1.107      1.175        114        640: 100%|| 237/237 [00:44<00:00,  5.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.636      0.707      0.703      0.615\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     30/100      2.17G     0.5911      1.101      1.169        125        640: 100%|| 237/237 [00:44<00:00,  5.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:03<00:00,  3.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.647      0.703       0.73      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     31/100      2.27G     0.5814      1.081      1.157        103        640: 100%|| 237/237 [00:44<00:00,  5.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.59it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.673      0.685      0.729       0.63\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     32/100      2.16G     0.5898      1.082      1.162        110        640: 100%|| 237/237 [00:44<00:00,  5.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.627      0.744      0.739       0.65\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     33/100       2.3G     0.5778       1.05      1.153        112        640: 100%|| 237/237 [00:44<00:00,  5.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.68it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.674      0.736      0.762      0.666\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     34/100      2.17G     0.5674      1.042      1.144         86        640: 100%|| 237/237 [00:44<00:00,  5.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.47it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.66      0.748       0.76      0.664\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     35/100       2.3G       0.56      1.016      1.141        129        640: 100%|| 237/237 [00:44<00:00,  5.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.688      0.737      0.775      0.684\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     36/100      2.27G     0.5565      1.016      1.136         98        640: 100%|| 237/237 [00:45<00:00,  5.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.701      0.721      0.776      0.688\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     37/100      2.17G     0.5593          1      1.136        116        640: 100%|| 237/237 [00:44<00:00,  5.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.67it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.711      0.727      0.786      0.692\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     38/100      2.18G     0.5579     0.9925      1.134        124        640: 100%|| 237/237 [00:45<00:00,  5.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.57it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.716      0.718       0.79        0.7\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     39/100      2.18G     0.5511     0.9755      1.127        109        640: 100%|| 237/237 [00:44<00:00,  5.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.75it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.713      0.742      0.792      0.705\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     40/100      2.29G     0.5514     0.9681      1.129        123        640: 100%|| 237/237 [00:44<00:00,  5.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.767       0.75      0.821       0.73\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     41/100       2.3G     0.5433     0.9513      1.124        105        640: 100%|| 237/237 [00:44<00:00,  5.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.704      0.705      0.762      0.679\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     42/100      2.27G     0.5445     0.9479      1.121        123        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.57it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.742      0.761      0.817      0.735\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     43/100      2.16G     0.5405     0.9378       1.12        105        640: 100%|| 237/237 [00:44<00:00,  5.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.68it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.76      0.737       0.82      0.733\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     44/100      2.19G     0.5338     0.9286      1.113        137        640: 100%|| 237/237 [00:45<00:00,  5.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.744      0.761      0.822      0.732\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     45/100       2.3G     0.5251     0.9022      1.106        119        640: 100%|| 237/237 [00:44<00:00,  5.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.755      0.777      0.834       0.75\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     46/100      2.17G     0.5246     0.8943      1.107        116        640: 100%|| 237/237 [00:45<00:00,  5.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.74      0.807      0.845      0.763\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     47/100      2.27G     0.5191     0.8954      1.102        126        640: 100%|| 237/237 [00:44<00:00,  5.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.60it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.762      0.772      0.839      0.751\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     48/100       2.3G     0.5208      0.875      1.098        115        640: 100%|| 237/237 [00:45<00:00,  5.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.776      0.818      0.864       0.78\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     49/100      2.17G     0.5147      0.864      1.097        124        640: 100%|| 237/237 [00:44<00:00,  5.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.79      0.804      0.867      0.785\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     50/100      2.16G     0.5116     0.8476      1.092        121        640: 100%|| 237/237 [00:45<00:00,  5.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.66it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.817      0.781      0.865      0.779\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     51/100      2.27G     0.4993     0.8331      1.084        148        640: 100%|| 237/237 [00:44<00:00,  5.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.783      0.798      0.866      0.788\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     52/100       2.3G     0.5065     0.8373      1.088        107        640: 100%|| 237/237 [00:44<00:00,  5.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.68it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.84      0.781      0.878        0.8\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     53/100      2.27G     0.5066     0.8199      1.088        125        640: 100%|| 237/237 [00:44<00:00,  5.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.23it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.833      0.809      0.884      0.803\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     54/100      2.16G     0.4957      0.816      1.081        134        640: 100%|| 237/237 [00:44<00:00,  5.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.65it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.84      0.787      0.885      0.808\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     55/100      2.29G     0.4915     0.7993      1.079        100        640: 100%|| 237/237 [00:44<00:00,  5.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.853      0.813      0.892      0.812\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     56/100      2.17G     0.4883     0.7995      1.075         97        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.63it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.811      0.818      0.887      0.812\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     57/100       2.3G     0.4921     0.7906      1.074        117        640: 100%|| 237/237 [00:44<00:00,  5.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.68it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.841      0.814      0.894      0.818\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     58/100      2.16G     0.4866     0.7805      1.071        129        640: 100%|| 237/237 [00:44<00:00,  5.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.835      0.823      0.892      0.811\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     59/100       2.3G     0.4842     0.7782      1.068         94        640: 100%|| 237/237 [00:44<00:00,  5.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.75it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.825       0.83      0.893      0.819\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     60/100      2.29G      0.478     0.7672      1.066        116        640: 100%|| 237/237 [00:44<00:00,  5.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.77it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.842      0.828        0.9      0.827\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     61/100       2.3G     0.4814     0.7692      1.067        129        640: 100%|| 237/237 [00:44<00:00,  5.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.837      0.823      0.895      0.821\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     62/100      2.17G     0.4791     0.7571      1.063        139        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.69it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.855      0.828        0.9      0.827\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     63/100      2.17G     0.4753     0.7451       1.06         99        640: 100%|| 237/237 [00:44<00:00,  5.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.86       0.82      0.906      0.832\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     64/100      2.16G      0.475     0.7379      1.062        119        640: 100%|| 237/237 [00:44<00:00,  5.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.844      0.848      0.906      0.838\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     65/100       2.3G     0.4683     0.7202      1.053        125        640: 100%|| 237/237 [00:44<00:00,  5.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.66it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.877      0.824      0.906      0.831\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     66/100      2.27G     0.4634     0.7233      1.053         97        640: 100%|| 237/237 [00:44<00:00,  5.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.852       0.85      0.907      0.835\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     67/100      2.27G     0.4675     0.7218      1.053        124        640: 100%|| 237/237 [00:44<00:00,  5.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.891      0.825      0.917      0.849\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     68/100      2.16G     0.4579     0.7109      1.046         99        640: 100%|| 237/237 [00:44<00:00,  5.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.892      0.847      0.919      0.849\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     69/100      2.27G     0.4547      0.696      1.044        141        640: 100%|| 237/237 [00:45<00:00,  5.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.865       0.85      0.918       0.85\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     70/100      2.29G     0.4537     0.6911      1.045        123        640: 100%|| 237/237 [00:44<00:00,  5.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.69it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.858      0.861       0.92      0.856\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     71/100      2.29G     0.4549     0.6854      1.044        154        640: 100%|| 237/237 [00:44<00:00,  5.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.75it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.888      0.842      0.918      0.852\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     72/100      2.27G      0.446     0.6794      1.035        126        640: 100%|| 237/237 [00:44<00:00,  5.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.861      0.855      0.918       0.85\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     73/100      2.29G     0.4502     0.6708      1.036        116        640: 100%|| 237/237 [00:44<00:00,  5.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.881      0.867      0.925      0.859\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     74/100      2.27G     0.4472     0.6689      1.039        128        640: 100%|| 237/237 [00:44<00:00,  5.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.64it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.909      0.827      0.921      0.856\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     75/100      2.27G     0.4455      0.665      1.036        130        640: 100%|| 237/237 [00:44<00:00,  5.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.891      0.863      0.927      0.864\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     76/100      2.27G     0.4392     0.6597      1.035         97        640: 100%|| 237/237 [00:42<00:00,  5.55it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.886      0.866      0.929      0.867\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     77/100       2.3G     0.4366     0.6599      1.026        100        640: 100%|| 237/237 [00:43<00:00,  5.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.883      0.872       0.93      0.866\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     78/100      2.29G     0.4343     0.6523      1.027        114        640: 100%|| 237/237 [00:42<00:00,  5.55it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.888      0.862      0.928      0.864\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     79/100       2.3G     0.4394     0.6476      1.029         86        640: 100%|| 237/237 [00:43<00:00,  5.51it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.877      0.857      0.924      0.859\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     80/100      2.17G     0.4313     0.6311      1.023        113        640: 100%|| 237/237 [00:42<00:00,  5.53it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.894      0.867      0.926      0.862\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     81/100      2.29G     0.4317      0.638      1.026        132        640: 100%|| 237/237 [00:43<00:00,  5.46it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.908      0.861      0.929      0.866\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     82/100      2.27G     0.4225     0.6173      1.016        152        640: 100%|| 237/237 [00:42<00:00,  5.54it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.894      0.863      0.929      0.865\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     83/100      2.29G     0.4212     0.6189      1.019        113        640: 100%|| 237/237 [00:43<00:00,  5.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.903      0.861      0.929      0.869\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     84/100      2.29G     0.4246     0.6323      1.023        145        640: 100%|| 237/237 [00:42<00:00,  5.52it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.99it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.905      0.861       0.93       0.87\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     85/100      2.27G     0.4182     0.6175      1.017        118        640: 100%|| 237/237 [00:42<00:00,  5.54it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.896      0.879      0.935      0.873\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     86/100      2.29G     0.4189     0.6087      1.018        101        640: 100%|| 237/237 [00:43<00:00,  5.50it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.899      0.883      0.933      0.872\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     87/100       2.3G     0.4143      0.605      1.011         87        640: 100%|| 237/237 [00:42<00:00,  5.55it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.923      0.861      0.935      0.875\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     88/100      2.16G     0.4143     0.6024      1.013        138        640: 100%|| 237/237 [00:43<00:00,  5.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  5.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.907      0.871      0.936      0.877\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     89/100      2.17G     0.4172     0.6003      1.015        131        640: 100%|| 237/237 [00:42<00:00,  5.56it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.912      0.878      0.939      0.879\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     90/100      2.17G     0.4086     0.5952      1.007        135        640: 100%|| 237/237 [00:43<00:00,  5.48it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.908       0.88      0.936      0.879\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     91/100      2.29G     0.3496     0.4196     0.9556         65        640: 100%|| 237/237 [00:43<00:00,  5.51it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.98it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.917      0.866      0.932      0.873\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     92/100      2.25G     0.3376      0.389     0.9473         65        640: 100%|| 237/237 [00:40<00:00,  5.83it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501        0.9      0.882      0.935      0.877\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     93/100      2.27G     0.3356      0.383     0.9467         50        640: 100%|| 237/237 [00:40<00:00,  5.83it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.911       0.88      0.938      0.882\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     94/100      2.25G     0.3328     0.3812     0.9461         70        640: 100%|| 237/237 [00:40<00:00,  5.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.66it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.918      0.884       0.94      0.884\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     95/100      2.27G     0.3306      0.372     0.9437         66        640: 100%|| 237/237 [00:40<00:00,  5.81it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.97it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.907      0.894      0.937      0.883\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     96/100      2.25G     0.3266      0.363     0.9412         71        640: 100%|| 237/237 [00:40<00:00,  5.90it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501       0.92      0.884       0.94      0.886\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     97/100      2.27G     0.3213     0.3575     0.9364         51        640: 100%|| 237/237 [00:40<00:00,  5.87it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.908      0.888      0.938      0.885\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     98/100      2.27G     0.3228     0.3546     0.9393         64        640: 100%|| 237/237 [00:40<00:00,  5.81it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.903      0.889      0.939      0.886\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     99/100      2.27G     0.3205     0.3523     0.9333         66        640: 100%|| 237/237 [00:40<00:00,  5.83it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.909      0.894       0.94      0.888\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"    100/100      2.25G     0.3184      0.345     0.9343         64        640: 100%|| 237/237 [00:40<00:00,  5.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:02<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.919      0.885       0.94      0.888\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n100 epochs completed in 1.331 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics YOLOv8.2.23  Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\nYOLOv8n summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:05<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        361       1501      0.909      0.894       0.94      0.888\n                   Cat        361        831      0.909       0.88      0.934      0.878\n                   Dog        361        670      0.908      0.907      0.945      0.898\nSpeed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 1.6ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='13.185 MB of 13.185 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td></td></tr><tr><td>lr/pg1</td><td></td></tr><tr><td>lr/pg2</td><td></td></tr><tr><td>metrics/mAP50(B)</td><td></td></tr><tr><td>metrics/mAP50-95(B)</td><td></td></tr><tr><td>metrics/precision(B)</td><td></td></tr><tr><td>metrics/recall(B)</td><td></td></tr><tr><td>model/GFLOPs</td><td></td></tr><tr><td>model/parameters</td><td></td></tr><tr><td>model/speed_PyTorch(ms)</td><td></td></tr><tr><td>train/box_loss</td><td></td></tr><tr><td>train/cls_loss</td><td></td></tr><tr><td>train/dfl_loss</td><td></td></tr><tr><td>val/box_loss</td><td></td></tr><tr><td>val/cls_loss</td><td></td></tr><tr><td>val/dfl_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>3e-05</td></tr><tr><td>lr/pg1</td><td>3e-05</td></tr><tr><td>lr/pg2</td><td>3e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.93974</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.88792</td></tr><tr><td>metrics/precision(B)</td><td>0.90887</td></tr><tr><td>metrics/recall(B)</td><td>0.89388</td></tr><tr><td>model/GFLOPs</td><td>8.195</td></tr><tr><td>model/parameters</td><td>3011238</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>3.502</td></tr><tr><td>train/box_loss</td><td>0.31838</td></tr><tr><td>train/cls_loss</td><td>0.34504</td></tr><tr><td>train/dfl_loss</td><td>0.9343</td></tr><tr><td>val/box_loss</td><td>0.32043</td></tr><tr><td>val/cls_loss</td><td>0.42068</td></tr><tr><td>val/dfl_loss</td><td>0.85324</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">train</strong> at: <a href='https://wandb.ai/arunnithyaanandam/YOLOv8/runs/nlcbuat4' target=\"_blank\">https://wandb.ai/arunnithyaanandam/YOLOv8/runs/nlcbuat4</a><br/> View project at: <a href='https://wandb.ai/arunnithyaanandam/YOLOv8' target=\"_blank\">https://wandb.ai/arunnithyaanandam/YOLOv8</a><br/>Synced 5 W&B file(s), 24 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240528_121543-nlcbuat4/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"model = YOLO('yolov8.yaml') \nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T15:42:11.479150Z","iopub.execute_input":"2024-05-28T15:42:11.479811Z","iopub.status.idle":"2024-05-28T15:42:11.609689Z","shell.execute_reply.started":"2024-05-28T15:42:11.479779Z","shell.execute_reply":"2024-05-28T15:42:11.608692Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"WARNING 锔 no model scale passed. Assuming scale='n'.\nYOLO(\n  (model): DetectionModel(\n    (model): Sequential(\n      (0): Conv(\n        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (1): Conv(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (2): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (3): Conv(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (4): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (5): Conv(\n        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (6): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (7): Conv(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (8): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (9): SPPF(\n        (cv1): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n      )\n      (10): Upsample(scale_factor=2.0, mode='nearest')\n      (11): Concat()\n      (12): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (13): Upsample(scale_factor=2.0, mode='nearest')\n      (14): Concat()\n      (15): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (16): Conv(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (17): Concat()\n      (18): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (19): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (20): Concat()\n      (21): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (22): Detect(\n        (cv2): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (cv3): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (dfl): DFL(\n          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    print(name)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T15:42:58.717806Z","iopub.execute_input":"2024-05-28T15:42:58.718516Z","iopub.status.idle":"2024-05-28T15:42:58.725203Z","shell.execute_reply.started":"2024-05-28T15:42:58.718486Z","shell.execute_reply":"2024-05-28T15:42:58.724369Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"model.model.0.conv.weight\nmodel.model.0.bn.weight\nmodel.model.0.bn.bias\nmodel.model.1.conv.weight\nmodel.model.1.bn.weight\nmodel.model.1.bn.bias\nmodel.model.2.cv1.conv.weight\nmodel.model.2.cv1.bn.weight\nmodel.model.2.cv1.bn.bias\nmodel.model.2.cv2.conv.weight\nmodel.model.2.cv2.bn.weight\nmodel.model.2.cv2.bn.bias\nmodel.model.2.m.0.cv1.conv.weight\nmodel.model.2.m.0.cv1.bn.weight\nmodel.model.2.m.0.cv1.bn.bias\nmodel.model.2.m.0.cv2.conv.weight\nmodel.model.2.m.0.cv2.bn.weight\nmodel.model.2.m.0.cv2.bn.bias\nmodel.model.3.conv.weight\nmodel.model.3.bn.weight\nmodel.model.3.bn.bias\nmodel.model.4.cv1.conv.weight\nmodel.model.4.cv1.bn.weight\nmodel.model.4.cv1.bn.bias\nmodel.model.4.cv2.conv.weight\nmodel.model.4.cv2.bn.weight\nmodel.model.4.cv2.bn.bias\nmodel.model.4.m.0.cv1.conv.weight\nmodel.model.4.m.0.cv1.bn.weight\nmodel.model.4.m.0.cv1.bn.bias\nmodel.model.4.m.0.cv2.conv.weight\nmodel.model.4.m.0.cv2.bn.weight\nmodel.model.4.m.0.cv2.bn.bias\nmodel.model.4.m.1.cv1.conv.weight\nmodel.model.4.m.1.cv1.bn.weight\nmodel.model.4.m.1.cv1.bn.bias\nmodel.model.4.m.1.cv2.conv.weight\nmodel.model.4.m.1.cv2.bn.weight\nmodel.model.4.m.1.cv2.bn.bias\nmodel.model.5.conv.weight\nmodel.model.5.bn.weight\nmodel.model.5.bn.bias\nmodel.model.6.cv1.conv.weight\nmodel.model.6.cv1.bn.weight\nmodel.model.6.cv1.bn.bias\nmodel.model.6.cv2.conv.weight\nmodel.model.6.cv2.bn.weight\nmodel.model.6.cv2.bn.bias\nmodel.model.6.m.0.cv1.conv.weight\nmodel.model.6.m.0.cv1.bn.weight\nmodel.model.6.m.0.cv1.bn.bias\nmodel.model.6.m.0.cv2.conv.weight\nmodel.model.6.m.0.cv2.bn.weight\nmodel.model.6.m.0.cv2.bn.bias\nmodel.model.6.m.1.cv1.conv.weight\nmodel.model.6.m.1.cv1.bn.weight\nmodel.model.6.m.1.cv1.bn.bias\nmodel.model.6.m.1.cv2.conv.weight\nmodel.model.6.m.1.cv2.bn.weight\nmodel.model.6.m.1.cv2.bn.bias\nmodel.model.7.conv.weight\nmodel.model.7.bn.weight\nmodel.model.7.bn.bias\nmodel.model.8.cv1.conv.weight\nmodel.model.8.cv1.bn.weight\nmodel.model.8.cv1.bn.bias\nmodel.model.8.cv2.conv.weight\nmodel.model.8.cv2.bn.weight\nmodel.model.8.cv2.bn.bias\nmodel.model.8.m.0.cv1.conv.weight\nmodel.model.8.m.0.cv1.bn.weight\nmodel.model.8.m.0.cv1.bn.bias\nmodel.model.8.m.0.cv2.conv.weight\nmodel.model.8.m.0.cv2.bn.weight\nmodel.model.8.m.0.cv2.bn.bias\nmodel.model.9.cv1.conv.weight\nmodel.model.9.cv1.bn.weight\nmodel.model.9.cv1.bn.bias\nmodel.model.9.cv2.conv.weight\nmodel.model.9.cv2.bn.weight\nmodel.model.9.cv2.bn.bias\nmodel.model.12.cv1.conv.weight\nmodel.model.12.cv1.bn.weight\nmodel.model.12.cv1.bn.bias\nmodel.model.12.cv2.conv.weight\nmodel.model.12.cv2.bn.weight\nmodel.model.12.cv2.bn.bias\nmodel.model.12.m.0.cv1.conv.weight\nmodel.model.12.m.0.cv1.bn.weight\nmodel.model.12.m.0.cv1.bn.bias\nmodel.model.12.m.0.cv2.conv.weight\nmodel.model.12.m.0.cv2.bn.weight\nmodel.model.12.m.0.cv2.bn.bias\nmodel.model.15.cv1.conv.weight\nmodel.model.15.cv1.bn.weight\nmodel.model.15.cv1.bn.bias\nmodel.model.15.cv2.conv.weight\nmodel.model.15.cv2.bn.weight\nmodel.model.15.cv2.bn.bias\nmodel.model.15.m.0.cv1.conv.weight\nmodel.model.15.m.0.cv1.bn.weight\nmodel.model.15.m.0.cv1.bn.bias\nmodel.model.15.m.0.cv2.conv.weight\nmodel.model.15.m.0.cv2.bn.weight\nmodel.model.15.m.0.cv2.bn.bias\nmodel.model.16.conv.weight\nmodel.model.16.bn.weight\nmodel.model.16.bn.bias\nmodel.model.18.cv1.conv.weight\nmodel.model.18.cv1.bn.weight\nmodel.model.18.cv1.bn.bias\nmodel.model.18.cv2.conv.weight\nmodel.model.18.cv2.bn.weight\nmodel.model.18.cv2.bn.bias\nmodel.model.18.m.0.cv1.conv.weight\nmodel.model.18.m.0.cv1.bn.weight\nmodel.model.18.m.0.cv1.bn.bias\nmodel.model.18.m.0.cv2.conv.weight\nmodel.model.18.m.0.cv2.bn.weight\nmodel.model.18.m.0.cv2.bn.bias\nmodel.model.19.conv.weight\nmodel.model.19.bn.weight\nmodel.model.19.bn.bias\nmodel.model.21.cv1.conv.weight\nmodel.model.21.cv1.bn.weight\nmodel.model.21.cv1.bn.bias\nmodel.model.21.cv2.conv.weight\nmodel.model.21.cv2.bn.weight\nmodel.model.21.cv2.bn.bias\nmodel.model.21.m.0.cv1.conv.weight\nmodel.model.21.m.0.cv1.bn.weight\nmodel.model.21.m.0.cv1.bn.bias\nmodel.model.21.m.0.cv2.conv.weight\nmodel.model.21.m.0.cv2.bn.weight\nmodel.model.21.m.0.cv2.bn.bias\nmodel.model.22.cv2.0.0.conv.weight\nmodel.model.22.cv2.0.0.bn.weight\nmodel.model.22.cv2.0.0.bn.bias\nmodel.model.22.cv2.0.1.conv.weight\nmodel.model.22.cv2.0.1.bn.weight\nmodel.model.22.cv2.0.1.bn.bias\nmodel.model.22.cv2.0.2.weight\nmodel.model.22.cv2.0.2.bias\nmodel.model.22.cv2.1.0.conv.weight\nmodel.model.22.cv2.1.0.bn.weight\nmodel.model.22.cv2.1.0.bn.bias\nmodel.model.22.cv2.1.1.conv.weight\nmodel.model.22.cv2.1.1.bn.weight\nmodel.model.22.cv2.1.1.bn.bias\nmodel.model.22.cv2.1.2.weight\nmodel.model.22.cv2.1.2.bias\nmodel.model.22.cv2.2.0.conv.weight\nmodel.model.22.cv2.2.0.bn.weight\nmodel.model.22.cv2.2.0.bn.bias\nmodel.model.22.cv2.2.1.conv.weight\nmodel.model.22.cv2.2.1.bn.weight\nmodel.model.22.cv2.2.1.bn.bias\nmodel.model.22.cv2.2.2.weight\nmodel.model.22.cv2.2.2.bias\nmodel.model.22.cv3.0.0.conv.weight\nmodel.model.22.cv3.0.0.bn.weight\nmodel.model.22.cv3.0.0.bn.bias\nmodel.model.22.cv3.0.1.conv.weight\nmodel.model.22.cv3.0.1.bn.weight\nmodel.model.22.cv3.0.1.bn.bias\nmodel.model.22.cv3.0.2.weight\nmodel.model.22.cv3.0.2.bias\nmodel.model.22.cv3.1.0.conv.weight\nmodel.model.22.cv3.1.0.bn.weight\nmodel.model.22.cv3.1.0.bn.bias\nmodel.model.22.cv3.1.1.conv.weight\nmodel.model.22.cv3.1.1.bn.weight\nmodel.model.22.cv3.1.1.bn.bias\nmodel.model.22.cv3.1.2.weight\nmodel.model.22.cv3.1.2.bias\nmodel.model.22.cv3.2.0.conv.weight\nmodel.model.22.cv3.2.0.bn.weight\nmodel.model.22.cv3.2.0.bn.bias\nmodel.model.22.cv3.2.1.conv.weight\nmodel.model.22.cv3.2.1.bn.weight\nmodel.model.22.cv3.2.1.bn.bias\nmodel.model.22.cv3.2.2.weight\nmodel.model.22.cv3.2.2.bias\nmodel.model.22.dfl.conv.weight\n","output_type":"stream"}]},{"cell_type":"code","source":"model=YOLO('yolov8.yaml')","metadata":{"execution":{"iopub.status.busy":"2024-05-28T17:03:19.887666Z","iopub.execute_input":"2024-05-28T17:03:19.888635Z","iopub.status.idle":"2024-05-28T17:03:20.018216Z","shell.execute_reply.started":"2024-05-28T17:03:19.888599Z","shell.execute_reply":"2024-05-28T17:03:20.017253Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"WARNING 锔 no model scale passed. Assuming scale='n'.\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in model.named_children():\n    print(i[1])","metadata":{"execution":{"iopub.status.busy":"2024-05-28T17:03:29.945876Z","iopub.execute_input":"2024-05-28T17:03:29.946607Z","iopub.status.idle":"2024-05-28T17:03:29.953751Z","shell.execute_reply.started":"2024-05-28T17:03:29.946575Z","shell.execute_reply":"2024-05-28T17:03:29.952845Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"DetectionModel(\n  (model): Sequential(\n    (0): Conv(\n      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (1): Conv(\n      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (2): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (3): Conv(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (4): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0-1): 2 x Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (5): Conv(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (6): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0-1): 2 x Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (7): Conv(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (8): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (9): SPPF(\n      (cv1): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n    )\n    (10): Upsample(scale_factor=2.0, mode='nearest')\n    (11): Concat()\n    (12): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (13): Upsample(scale_factor=2.0, mode='nearest')\n    (14): Concat()\n    (15): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (16): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (17): Concat()\n    (18): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (19): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (20): Concat()\n    (21): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (22): Detect(\n      (cv2): ModuleList(\n        (0): Sequential(\n          (0): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Sequential(\n          (0): Conv(\n            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Sequential(\n          (0): Conv(\n            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (cv3): ModuleList(\n        (0): Sequential(\n          (0): Conv(\n            (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Sequential(\n          (0): Conv(\n            (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Sequential(\n          (0): Conv(\n            (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (dfl): DFL(\n        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"help('ultralytics.nn.tasks.DetectionModel')","metadata":{"execution":{"iopub.status.busy":"2024-05-28T16:55:25.235564Z","iopub.execute_input":"2024-05-28T16:55:25.236236Z","iopub.status.idle":"2024-05-28T16:55:25.251637Z","shell.execute_reply.started":"2024-05-28T16:55:25.236204Z","shell.execute_reply":"2024-05-28T16:55:25.250713Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Help on class DetectionModel in ultralytics.nn.tasks:\n\nultralytics.nn.tasks.DetectionModel = class DetectionModel(BaseModel)\n |  ultralytics.nn.tasks.DetectionModel(cfg='yolov8n.yaml', ch=3, nc=None, verbose=True)\n |  \n |  YOLOv8 detection model.\n |  \n |  Method resolution order:\n |      DetectionModel\n |      BaseModel\n |      torch.nn.modules.module.Module\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, cfg='yolov8n.yaml', ch=3, nc=None, verbose=True)\n |      Initialize the YOLOv8 detection model with the given config and parameters.\n |  \n |  init_criterion(self)\n |      Initialize the loss criterion for the DetectionModel.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __annotations__ = {}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from BaseModel:\n |  \n |  forward(self, x, *args, **kwargs)\n |      Forward pass of the model on a single scale. Wrapper for `_forward_once` method.\n |      \n |      Args:\n |          x (torch.Tensor | dict): The input image tensor or a dict including image tensor and gt labels.\n |      \n |      Returns:\n |          (torch.Tensor): The output of the network.\n |  \n |  fuse(self, verbose=True)\n |      Fuse the `Conv2d()` and `BatchNorm2d()` layers of the model into a single layer, in order to improve the\n |      computation efficiency.\n |      \n |      Returns:\n |          (nn.Module): The fused model is returned.\n |  \n |  info(self, detailed=False, verbose=True, imgsz=640)\n |      Prints model information.\n |      \n |      Args:\n |          detailed (bool): if True, prints out detailed information about the model. Defaults to False\n |          verbose (bool): if True, prints out the model information. Defaults to False\n |          imgsz (int): the size of the image that the model will be trained on. Defaults to 640\n |  \n |  is_fused(self, thresh=10)\n |      Check if the model has less than a certain threshold of BatchNorm layers.\n |      \n |      Args:\n |          thresh (int, optional): The threshold number of BatchNorm layers. Default is 10.\n |      \n |      Returns:\n |          (bool): True if the number of BatchNorm layers in the model is less than the threshold, False otherwise.\n |  \n |  load(self, weights, verbose=True)\n |      Load the weights into the model.\n |      \n |      Args:\n |          weights (dict | torch.nn.Module): The pre-trained weights to be loaded.\n |          verbose (bool, optional): Whether to log the transfer progress. Defaults to True.\n |  \n |  loss(self, batch, preds=None)\n |      Compute loss.\n |      \n |      Args:\n |          batch (dict): Batch to compute loss on\n |          preds (torch.Tensor | List[torch.Tensor]): Predictions.\n |  \n |  predict(self, x, profile=False, visualize=False, augment=False, embed=None)\n |      Perform a forward pass through the network.\n |      \n |      Args:\n |          x (torch.Tensor): The input tensor to the model.\n |          profile (bool):  Print the computation time of each layer if True, defaults to False.\n |          visualize (bool): Save the feature maps of the model if True, defaults to False.\n |          augment (bool): Augment image during prediction, defaults to False.\n |          embed (list, optional): A list of feature vectors/embeddings to return.\n |      \n |      Returns:\n |          (torch.Tensor): The last output of the model.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from torch.nn.modules.module.Module:\n |  \n |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n |  \n |  __delattr__(self, name)\n |      Implement delattr(self, name).\n |  \n |  __dir__(self)\n |      Default dir() implementation.\n |  \n |  __getattr__(self, name: str) -> Any\n |      # On the return type:\n |      # We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\n |      # This is done for better interop with various type checkers for the end users.\n |      # Having a stricter return type doesn't play nicely with `register_buffer()` and forces\n |      # people to excessively use type-ignores, asserts, casts, etc.\n |      # See full discussion on the problems with returning `Union` here\n |      # https://github.com/microsoft/pyright/issues/4213\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n |      Implement setattr(self, name, value).\n |  \n |  __setstate__(self, state)\n |  \n |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n |      Adds a child module to the current module.\n |      \n |      The module can be accessed as an attribute using the given name.\n |      \n |      Args:\n |          name (str): name of the child module. The child module can be\n |              accessed from this module using the given name\n |          module (Module): child module to be added to the module.\n |  \n |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n |      as well as self. Typical use includes initializing the parameters of a model\n |      (see also :ref:`nn-init-doc`).\n |      \n |      Args:\n |          fn (:class:`Module` -> None): function to be applied to each submodule\n |      \n |      Returns:\n |          Module: self\n |      \n |      Example::\n |      \n |          >>> @torch.no_grad()\n |          >>> def init_weights(m):\n |          >>>     print(m)\n |          >>>     if type(m) == nn.Linear:\n |          >>>         m.weight.fill_(1.0)\n |          >>>         print(m.weight)\n |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n |          >>> net.apply(init_weights)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[1., 1.],\n |                  [1., 1.]], requires_grad=True)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[1., 1.],\n |                  [1., 1.]], requires_grad=True)\n |          Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |  \n |  bfloat16(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Returns:\n |          Module: self\n |  \n |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n |      Returns an iterator over module buffers.\n |      \n |      Args:\n |          recurse (bool): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module.\n |      \n |      Yields:\n |          torch.Tensor: module buffer\n |      \n |      Example::\n |      \n |          >>> # xdoctest: +SKIP(\"undefined vars\")\n |          >>> for buf in model.buffers():\n |          >>>     print(type(buf), buf.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  children(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over immediate children modules.\n |      \n |      Yields:\n |          Module: a child module\n |  \n |  compile(self, *args, **kwargs)\n |      Compile this Module's forward using :func:`torch.compile`.\n |      \n |      This Module's `__call__` method is compiled and all arguments are passed as-is\n |      to :func:`torch.compile`.\n |      \n |      See :func:`torch.compile` for details on the arguments for this function.\n |  \n |  cpu(self: ~T) -> ~T\n |      Moves all model parameters and buffers to the CPU.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Returns:\n |          Module: self\n |  \n |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n |      Moves all model parameters and buffers to the GPU.\n |      \n |      This also makes associated parameters and buffers different objects. So\n |      it should be called before constructing optimizer if the module will\n |      live on GPU while being optimized.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Args:\n |          device (int, optional): if specified, all parameters will be\n |              copied to that device\n |      \n |      Returns:\n |          Module: self\n |  \n |  double(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``double`` datatype.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Returns:\n |          Module: self\n |  \n |  eval(self: ~T) -> ~T\n |      Sets the module in evaluation mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n |      \n |      See :ref:`locally-disable-grad-doc` for a comparison between\n |      `.eval()` and several similar mechanisms that may be confused with it.\n |      \n |      Returns:\n |          Module: self\n |  \n |  extra_repr(self) -> str\n |      Set the extra representation of the module\n |      \n |      To print customized extra information, you should re-implement\n |      this method in your own modules. Both single-line and multi-line\n |      strings are acceptable.\n |  \n |  float(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``float`` datatype.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Returns:\n |          Module: self\n |  \n |  get_buffer(self, target: str) -> 'Tensor'\n |      Returns the buffer given by ``target`` if it exists,\n |      otherwise throws an error.\n |      \n |      See the docstring for ``get_submodule`` for a more detailed\n |      explanation of this method's functionality as well as how to\n |      correctly specify ``target``.\n |      \n |      Args:\n |          target: The fully-qualified string name of the buffer\n |              to look for. (See ``get_submodule`` for how to specify a\n |              fully-qualified string.)\n |      \n |      Returns:\n |          torch.Tensor: The buffer referenced by ``target``\n |      \n |      Raises:\n |          AttributeError: If the target string references an invalid\n |              path or resolves to something that is not a\n |              buffer\n |  \n |  get_extra_state(self) -> Any\n |      Returns any extra state to include in the module's state_dict.\n |      Implement this and a corresponding :func:`set_extra_state` for your module\n |      if you need to store extra state. This function is called when building the\n |      module's `state_dict()`.\n |      \n |      Note that extra state should be picklable to ensure working serialization\n |      of the state_dict. We only provide provide backwards compatibility guarantees\n |      for serializing Tensors; other objects may break backwards compatibility if\n |      their serialized pickled form changes.\n |      \n |      Returns:\n |          object: Any extra state to store in the module's state_dict\n |  \n |  get_parameter(self, target: str) -> 'Parameter'\n |      Returns the parameter given by ``target`` if it exists,\n |      otherwise throws an error.\n |      \n |      See the docstring for ``get_submodule`` for a more detailed\n |      explanation of this method's functionality as well as how to\n |      correctly specify ``target``.\n |      \n |      Args:\n |          target: The fully-qualified string name of the Parameter\n |              to look for. (See ``get_submodule`` for how to specify a\n |              fully-qualified string.)\n |      \n |      Returns:\n |          torch.nn.Parameter: The Parameter referenced by ``target``\n |      \n |      Raises:\n |          AttributeError: If the target string references an invalid\n |              path or resolves to something that is not an\n |              ``nn.Parameter``\n |  \n |  get_submodule(self, target: str) -> 'Module'\n |      Returns the submodule given by ``target`` if it exists,\n |      otherwise throws an error.\n |      \n |      For example, let's say you have an ``nn.Module`` ``A`` that\n |      looks like this:\n |      \n |      .. code-block:: text\n |      \n |          A(\n |              (net_b): Module(\n |                  (net_c): Module(\n |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n |                  )\n |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n |              )\n |          )\n |      \n |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n |      submodule ``net_b``, which itself has two submodules ``net_c``\n |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n |      \n |      To check whether or not we have the ``linear`` submodule, we\n |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n |      we have the ``conv`` submodule, we would call\n |      ``get_submodule(\"net_b.net_c.conv\")``.\n |      \n |      The runtime of ``get_submodule`` is bounded by the degree\n |      of module nesting in ``target``. A query against\n |      ``named_modules`` achieves the same result, but it is O(N) in\n |      the number of transitive modules. So, for a simple check to see\n |      if some submodule exists, ``get_submodule`` should always be\n |      used.\n |      \n |      Args:\n |          target: The fully-qualified string name of the submodule\n |              to look for. (See above example for how to specify a\n |              fully-qualified string.)\n |      \n |      Returns:\n |          torch.nn.Module: The submodule referenced by ``target``\n |      \n |      Raises:\n |          AttributeError: If the target string references an invalid\n |              path or resolves to something that is not an\n |              ``nn.Module``\n |  \n |  half(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``half`` datatype.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Returns:\n |          Module: self\n |  \n |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n |      Moves all model parameters and buffers to the IPU.\n |      \n |      This also makes associated parameters and buffers different objects. So\n |      it should be called before constructing optimizer if the module will\n |      live on IPU while being optimized.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Arguments:\n |          device (int, optional): if specified, all parameters will be\n |              copied to that device\n |      \n |      Returns:\n |          Module: self\n |  \n |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False)\n |      Copies parameters and buffers from :attr:`state_dict` into\n |      this module and its descendants. If :attr:`strict` is ``True``, then\n |      the keys of :attr:`state_dict` must exactly match the keys returned\n |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n |      \n |      .. warning::\n |          If :attr:`assign` is ``True`` the optimizer must be created after\n |          the call to :attr:`load_state_dict`.\n |      \n |      Args:\n |          state_dict (dict): a dict containing parameters and\n |              persistent buffers.\n |          strict (bool, optional): whether to strictly enforce that the keys\n |              in :attr:`state_dict` match the keys returned by this module's\n |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n |          assign (bool, optional): whether to assign items in the state\n |              dictionary to their corresponding keys in the module instead\n |              of copying them inplace into the module's current parameters and buffers.\n |              When ``False``, the properties of the tensors in the current\n |              module are preserved while when ``True``, the properties of the\n |              Tensors in the state dict are preserved.\n |              Default: ``False``\n |      \n |      Returns:\n |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n |              * **missing_keys** is a list of str containing the missing keys\n |              * **unexpected_keys** is a list of str containing the unexpected keys\n |      \n |      Note:\n |          If a parameter or buffer is registered as ``None`` and its corresponding key\n |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n |          ``RuntimeError``.\n |  \n |  modules(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over all modules in the network.\n |      \n |      Yields:\n |          Module: a module in the network\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.modules()):\n |          ...     print(idx, '->', m)\n |      \n |          0 -> Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |          1 -> Linear(in_features=2, out_features=2, bias=True)\n |  \n |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n |      Returns an iterator over module buffers, yielding both the\n |      name of the buffer as well as the buffer itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all buffer names.\n |          recurse (bool, optional): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module. Defaults to True.\n |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n |      \n |      Yields:\n |          (str, torch.Tensor): Tuple containing the name and buffer\n |      \n |      Example::\n |      \n |          >>> # xdoctest: +SKIP(\"undefined vars\")\n |          >>> for name, buf in self.named_buffers():\n |          >>>     if name in ['running_var']:\n |          >>>         print(buf.size())\n |  \n |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n |      Returns an iterator over immediate children modules, yielding both\n |      the name of the module as well as the module itself.\n |      \n |      Yields:\n |          (str, Module): Tuple containing a name and child module\n |      \n |      Example::\n |      \n |          >>> # xdoctest: +SKIP(\"undefined vars\")\n |          >>> for name, module in model.named_children():\n |          >>>     if name in ['conv4', 'conv5']:\n |          >>>         print(module)\n |  \n |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n |      Returns an iterator over all modules in the network, yielding\n |      both the name of the module as well as the module itself.\n |      \n |      Args:\n |          memo: a memo to store the set of modules already added to the result\n |          prefix: a prefix that will be added to the name of the module\n |          remove_duplicate: whether to remove the duplicated module instances in the result\n |              or not\n |      \n |      Yields:\n |          (str, Module): Tuple of name and module\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.named_modules()):\n |          ...     print(idx, '->', m)\n |      \n |          0 -> ('', Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          ))\n |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n |  \n |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n |      Returns an iterator over module parameters, yielding both the\n |      name of the parameter as well as the parameter itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all parameter names.\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |          remove_duplicate (bool, optional): whether to remove the duplicated\n |              parameters in the result. Defaults to True.\n |      \n |      Yields:\n |          (str, Parameter): Tuple containing the name and parameter\n |      \n |      Example::\n |      \n |          >>> # xdoctest: +SKIP(\"undefined vars\")\n |          >>> for name, param in self.named_parameters():\n |          >>>     if name in ['bias']:\n |          >>>         print(param.size())\n |  \n |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n |      Returns an iterator over module parameters.\n |      \n |      This is typically passed to an optimizer.\n |      \n |      Args:\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |      \n |      Yields:\n |          Parameter: module parameter\n |      \n |      Example::\n |      \n |          >>> # xdoctest: +SKIP(\"undefined vars\")\n |          >>> for param in model.parameters():\n |          >>>     print(type(param), param.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n |      Registers a backward hook on the module.\n |      \n |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n |      the behavior of this function will change in future versions.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n |      Adds a buffer to the module.\n |      \n |      This is typically used to register a buffer that should not to be\n |      considered a model parameter. For example, BatchNorm's ``running_mean``\n |      is not a parameter, but is part of the module's state. Buffers, by\n |      default, are persistent and will be saved alongside parameters. This\n |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n |      only difference between a persistent buffer and a non-persistent buffer\n |      is that the latter will not be a part of this module's\n |      :attr:`state_dict`.\n |      \n |      Buffers can be accessed as attributes using given names.\n |      \n |      Args:\n |          name (str): name of the buffer. The buffer can be accessed\n |              from this module using the given name\n |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n |              the buffer is **not** included in the module's :attr:`state_dict`.\n |          persistent (bool): whether the buffer is part of this module's\n |              :attr:`state_dict`.\n |      \n |      Example::\n |      \n |          >>> # xdoctest: +SKIP(\"undefined vars\")\n |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n |  \n |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward hook on the module.\n |      \n |      The hook will be called every time after :func:`forward` has computed an output.\n |      \n |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n |      the positional arguments given to the module. Keyword arguments won't be\n |      passed to the hooks and only to the ``forward``. The hook can modify the\n |      output. It can modify the input inplace but it will not have effect on\n |      forward since this is called after :func:`forward` is called. The hook\n |      should have the following signature::\n |      \n |          hook(module, args, output) -> None or modified output\n |      \n |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n |      ``kwargs`` given to the forward function and be expected to return the\n |      output possibly modified. The hook should have the following signature::\n |      \n |          hook(module, args, kwargs, output) -> None or modified output\n |      \n |      Args:\n |          hook (Callable): The user defined hook to be registered.\n |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n |              before all existing ``forward`` hooks on this\n |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n |              ``hook`` will be fired after all existing ``forward`` hooks on\n |              this :class:`torch.nn.modules.Module`. Note that global\n |              ``forward`` hooks registered with\n |              :func:`register_module_forward_hook` will fire before all hooks\n |              registered by this method.\n |              Default: ``False``\n |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n |              kwargs given to the forward function.\n |              Default: ``False``\n |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n |              whether an exception is raised while calling the Module.\n |              Default: ``False``\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward pre-hook on the module.\n |      \n |      The hook will be called every time before :func:`forward` is invoked.\n |      \n |      \n |      If ``with_kwargs`` is false or not specified, the input contains only\n |      the positional arguments given to the module. Keyword arguments won't be\n |      passed to the hooks and only to the ``forward``. The hook can modify the\n |      input. User can either return a tuple or a single modified value in the\n |      hook. We will wrap the value into a tuple if a single value is returned\n |      (unless that value is already a tuple). The hook should have the\n |      following signature::\n |      \n |          hook(module, args) -> None or modified input\n |      \n |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n |      kwargs given to the forward function. And if the hook modifies the\n |      input, both the args and kwargs should be returned. The hook should have\n |      the following signature::\n |      \n |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n |      \n |      Args:\n |          hook (Callable): The user defined hook to be registered.\n |          prepend (bool): If true, the provided ``hook`` will be fired before\n |              all existing ``forward_pre`` hooks on this\n |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n |              on this :class:`torch.nn.modules.Module`. Note that global\n |              ``forward_pre`` hooks registered with\n |              :func:`register_module_forward_pre_hook` will fire before all\n |              hooks registered by this method.\n |              Default: ``False``\n |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n |              given to the forward function.\n |              Default: ``False``\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n |      Registers a backward hook on the module.\n |      \n |      The hook will be called every time the gradients with respect to a module\n |      are computed, i.e. the hook will execute if and only if the gradients with\n |      respect to module outputs are computed. The hook should have the following\n |      signature::\n |      \n |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n |      \n |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n |      with respect to the inputs and outputs respectively. The hook should\n |      not modify its arguments, but it can optionally return a new gradient with\n |      respect to the input that will be used in place of :attr:`grad_input` in\n |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n |      as positional arguments and all kwarg arguments are ignored. Entries\n |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n |      arguments.\n |      \n |      For technical reasons, when this hook is applied to a Module, its forward function will\n |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n |      of each Tensor returned by the Module's forward function.\n |      \n |      .. warning ::\n |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n |          will raise an error.\n |      \n |      Args:\n |          hook (Callable): The user-defined hook to be registered.\n |          prepend (bool): If true, the provided ``hook`` will be fired before\n |              all existing ``backward`` hooks on this\n |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n |              ``hook`` will be fired after all existing ``backward`` hooks on\n |              this :class:`torch.nn.modules.Module`. Note that global\n |              ``backward`` hooks registered with\n |              :func:`register_module_full_backward_hook` will fire before\n |              all hooks registered by this method.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n |      Registers a backward pre-hook on the module.\n |      \n |      The hook will be called every time the gradients for the module are computed.\n |      The hook should have the following signature::\n |      \n |          hook(module, grad_output) -> tuple[Tensor] or None\n |      \n |      The :attr:`grad_output` is a tuple. The hook should\n |      not modify its arguments, but it can optionally return a new gradient with\n |      respect to the output that will be used in place of :attr:`grad_output` in\n |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n |      all non-Tensor arguments.\n |      \n |      For technical reasons, when this hook is applied to a Module, its forward function will\n |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n |      of each Tensor returned by the Module's forward function.\n |      \n |      .. warning ::\n |          Modifying inputs inplace is not allowed when using backward hooks and\n |          will raise an error.\n |      \n |      Args:\n |          hook (Callable): The user-defined hook to be registered.\n |          prepend (bool): If true, the provided ``hook`` will be fired before\n |              all existing ``backward_pre`` hooks on this\n |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n |              on this :class:`torch.nn.modules.Module`. Note that global\n |              ``backward_pre`` hooks registered with\n |              :func:`register_module_full_backward_pre_hook` will fire before\n |              all hooks registered by this method.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_load_state_dict_post_hook(self, hook)\n |      Registers a post hook to be run after module's ``load_state_dict``\n |      is called.\n |      \n |      It should have the following signature::\n |          hook(module, incompatible_keys) -> None\n |      \n |      The ``module`` argument is the current module that this hook is registered\n |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n |      is a ``list`` of ``str`` containing the missing keys and\n |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n |      \n |      The given incompatible_keys can be modified inplace if needed.\n |      \n |      Note that the checks performed when calling :func:`load_state_dict` with\n |      ``strict=True`` are affected by modifications the hook makes to\n |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n |      set of keys will result in an error being thrown when ``strict=True``, and\n |      clearing out both missing and unexpected keys will avoid an error.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n |      Alias for :func:`add_module`.\n |  \n |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n |      Adds a parameter to the module.\n |      \n |      The parameter can be accessed as an attribute using given name.\n |      \n |      Args:\n |          name (str): name of the parameter. The parameter can be accessed\n |              from this module using the given name\n |          param (Parameter or None): parameter to be added to the module. If\n |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n |              are ignored. If ``None``, the parameter is **not** included in the\n |              module's :attr:`state_dict`.\n |  \n |  register_state_dict_pre_hook(self, hook)\n |      These hooks will be called with arguments: ``self``, ``prefix``,\n |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n |      hooks can be used to perform pre-processing before the ``state_dict``\n |      call is made.\n |  \n |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n |      Change if autograd should record operations on parameters in this\n |      module.\n |      \n |      This method sets the parameters' :attr:`requires_grad` attributes\n |      in-place.\n |      \n |      This method is helpful for freezing part of the module for finetuning\n |      or training parts of a model individually (e.g., GAN training).\n |      \n |      See :ref:`locally-disable-grad-doc` for a comparison between\n |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n |      \n |      Args:\n |          requires_grad (bool): whether autograd should record operations on\n |                                parameters in this module. Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  set_extra_state(self, state: Any)\n |      This function is called from :func:`load_state_dict` to handle any extra state\n |      found within the `state_dict`. Implement this function and a corresponding\n |      :func:`get_extra_state` for your module if you need to store extra state within its\n |      `state_dict`.\n |      \n |      Args:\n |          state (dict): Extra state from the `state_dict`\n |  \n |  share_memory(self: ~T) -> ~T\n |      See :meth:`torch.Tensor.share_memory_`\n |  \n |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n |      Returns a dictionary containing references to the whole state of the module.\n |      \n |      Both parameters and persistent buffers (e.g. running averages) are\n |      included. Keys are corresponding parameter and buffer names.\n |      Parameters and buffers set to ``None`` are not included.\n |      \n |      .. note::\n |          The returned object is a shallow copy. It contains references\n |          to the module's parameters and buffers.\n |      \n |      .. warning::\n |          Currently ``state_dict()`` also accepts positional arguments for\n |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n |          this is being deprecated and keyword arguments will be enforced in\n |          future releases.\n |      \n |      .. warning::\n |          Please avoid the use of argument ``destination`` as it is not\n |          designed for end-users.\n |      \n |      Args:\n |          destination (dict, optional): If provided, the state of module will\n |              be updated into the dict and the same object is returned.\n |              Otherwise, an ``OrderedDict`` will be created and returned.\n |              Default: ``None``.\n |          prefix (str, optional): a prefix added to parameter and buffer\n |              names to compose the keys in state_dict. Default: ``''``.\n |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n |              returned in the state dict are detached from autograd. If it's\n |              set to ``True``, detaching will not be performed.\n |              Default: ``False``.\n |      \n |      Returns:\n |          dict:\n |              a dictionary containing a whole state of the module\n |      \n |      Example::\n |      \n |          >>> # xdoctest: +SKIP(\"undefined vars\")\n |          >>> module.state_dict().keys()\n |          ['bias', 'weight']\n |  \n |  to(self, *args, **kwargs)\n |      Moves and/or casts the parameters and buffers.\n |      \n |      This can be called as\n |      \n |      .. function:: to(device=None, dtype=None, non_blocking=False)\n |         :noindex:\n |      \n |      .. function:: to(dtype, non_blocking=False)\n |         :noindex:\n |      \n |      .. function:: to(tensor, non_blocking=False)\n |         :noindex:\n |      \n |      .. function:: to(memory_format=torch.channels_last)\n |         :noindex:\n |      \n |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n |      (if given). The integral parameters and buffers will be moved\n |      :attr:`device`, if that is given, but with dtypes unchanged. When\n |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n |      with respect to the host if possible, e.g., moving CPU Tensors with\n |      pinned memory to CUDA devices.\n |      \n |      See below for examples.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Args:\n |          device (:class:`torch.device`): the desired device of the parameters\n |              and buffers in this module\n |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n |              the parameters and buffers in this module\n |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n |              dtype and device for all parameters and buffers in this module\n |          memory_format (:class:`torch.memory_format`): the desired memory\n |              format for 4D parameters and buffers in this module (keyword\n |              only argument)\n |      \n |      Returns:\n |          Module: self\n |      \n |      Examples::\n |      \n |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n |          >>> linear = nn.Linear(2, 2)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]])\n |          >>> linear.to(torch.double)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]], dtype=torch.float64)\n |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n |          >>> gpu1 = torch.device(\"cuda:1\")\n |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n |          >>> cpu = torch.device(\"cpu\")\n |          >>> linear.to(cpu)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16)\n |      \n |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n |          tensor([[0.6122+0.j, 0.1150+0.j],\n |                  [0.6122+0.j, 0.1150+0.j],\n |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n |  \n |  to_empty(self: ~T, *, device: Union[str, torch.device], recurse: bool = True) -> ~T\n |      Moves the parameters and buffers to the specified device without copying storage.\n |      \n |      Args:\n |          device (:class:`torch.device`): The desired device of the parameters\n |              and buffers in this module.\n |          recurse (bool): Whether parameters and buffers of submodules should\n |              be recursively moved to the specified device.\n |      \n |      Returns:\n |          Module: self\n |  \n |  train(self: ~T, mode: bool = True) -> ~T\n |      Sets the module in training mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      Args:\n |          mode (bool): whether to set training mode (``True``) or evaluation\n |                       mode (``False``). Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n |      Casts all parameters and buffers to :attr:`dst_type`.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Args:\n |          dst_type (type or string): the desired type\n |      \n |      Returns:\n |          Module: self\n |  \n |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n |      Moves all model parameters and buffers to the XPU.\n |      \n |      This also makes associated parameters and buffers different objects. So\n |      it should be called before constructing optimizer if the module will\n |      live on XPU while being optimized.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Arguments:\n |          device (int, optional): if specified, all parameters will be\n |              copied to that device\n |      \n |      Returns:\n |          Module: self\n |  \n |  zero_grad(self, set_to_none: bool = True) -> None\n |      Resets gradients of all model parameters. See similar function\n |      under :class:`torch.optim.Optimizer` for more context.\n |      \n |      Args:\n |          set_to_none (bool): instead of setting to zero, set the grads to None.\n |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from torch.nn.modules.module.Module:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from torch.nn.modules.module.Module:\n |  \n |  T_destination = ~T_destination\n |  \n |  call_super_init = False\n |  \n |  dump_patches = False\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T16:57:23.087725Z","iopub.execute_input":"2024-05-28T16:57:23.088347Z","iopub.status.idle":"2024-05-28T16:57:23.095807Z","shell.execute_reply.started":"2024-05-28T16:57:23.088313Z","shell.execute_reply":"2024-05-28T16:57:23.094843Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"('model', DetectionModel(\n  (model): Sequential(\n    (0): Conv(\n      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (1): Conv(\n      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (2): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (3): Conv(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (4): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0-1): 2 x Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (5): Conv(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (6): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0-1): 2 x Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (7): Conv(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (8): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (9): SPPF(\n      (cv1): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n    )\n    (10): Upsample(scale_factor=2.0, mode='nearest')\n    (11): Concat()\n    (12): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (13): Upsample(scale_factor=2.0, mode='nearest')\n    (14): Concat()\n    (15): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (16): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (17): Concat()\n    (18): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (19): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (20): Concat()\n    (21): C2f(\n      (cv1): Conv(\n        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): ModuleList(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (22): Detect(\n      (cv2): ModuleList(\n        (0): Sequential(\n          (0): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Sequential(\n          (0): Conv(\n            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Sequential(\n          (0): Conv(\n            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (cv3): ModuleList(\n        (0): Sequential(\n          (0): Conv(\n            (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Sequential(\n          (0): Conv(\n            (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Sequential(\n          (0): Conv(\n            (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (1): Conv(\n            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (dfl): DFL(\n        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      )\n    )\n  )\n))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}